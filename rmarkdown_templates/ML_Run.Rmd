---
title: "ML_Run"
output: html_document
---


```{r setup, echo=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
# code for checking predictors
if(!require(tidyverse)) install.packages("tidyverse")
if(!require(summarytools)) install.packages("summarytools")
if(!require(sjlabelled)) install.packages("sjlabelled")
if(!require(kableExtra)) install.packages("kableExtra")
if(!require(sjPlot)) install.packages("sjPlot")
sapply(c("tidyverse","summarytools","sjlabelled", "kableExtra", "sjPlot"), library, character.only = TRUE)
```


```{r data_code, echo=FALSE, include=FALSE}
library(haven)
## Alternatively import data in coded format (haven::read_sav)
# Step 1. Load data saved (following the "generate_clean_data.R)
lgbti_sav <- readRDS("~/Desktop/Master Project/Data/LGBTI/data/clean/lgbti_sav.rds")
lgbti_dta <- readRDS("~/Desktop/Master Project/Data/LGBTI/data/clean/lgbti_dta.rds")
# Step 2. Extract question labels from the .dta dataset and put them to the sav dataset
# a. Derive variable labels from the .dta dataset
var_labs <- map_chr(lgbti_dta, ~ attributes(.)$label)
# b. Attach labels to the .sav dataset
data_coded <- set_label(lgbti_sav,var_labs)
## Step 3. Extract HTML document fully describing the data, their categories and answer options
library(sjPlot) #sjPlot is required
var_desc<-data_coded %>% sjPlot::view_df() 
print(var_desc)
```


```{r data_label, echo=FALSE, include=FALSE}

# Step 1. Load data saved (following the "generate_clean_data.R)
lgbti_sav <- readRDS("~/Desktop/Master Project/Data/LGBTI/data/clean/lgbti_sav.rds")
```

```{r train_test_datasets, echo=FALSE, include=FALSE}
## 1st Function: First approach to create a training and test dataset
######################  
## NOTE: There are alternative ways of producing the train dataset, e.g. giving probabilities. Currently we keep it simple
######################  

train_test_sets<-function(data, seed, perc_sample){
## Data: input data to be subsetted to create the training and test datasets
set.seed(seed)
data_excl<- data %>% filter(!is.na(open_at_work)) ## Does this work for the labeled data?
sample <- sample.int(n = nrow(data_excl), size = floor(perc_sample*nrow(data_excl)), replace = F)
data_train <- data_excl[sample, ]
data_test <- data_excl[-sample, ]
res<-list( "data_train" = data_train, "data_test"=data_test)
return(res)
}

## Call the function ##
data_all<-train_test_sets(lgbti_sav, seed=123, perc_sample=0.70)
data.train<-data_all$data_train
data.test<-data_all$data_test
```

```{r predictors, echo=FALSE}
## 2nd Function: Subsetting the dataset for selecting target variable and predictors
data_target<-function(data, target_var, predictors){
data_sel <- data %>%
            filter(!is.na(!!as.name(target_var))) %>% ## do not consider rows where the predictor is NA
            select(c(!!as.name(target_var), !!(predictors)))
return(data_sel)
}
                             
## Call the function (currently a limited subset of predictors are considered for testing purposes)
## predictors
pred_var<-c("RESPONDENT_CATEGORY","A1", "A2", "A10", "A11", "A11_1", "A13", "A14", "B1", "B2", "C1_A", "C1_B", "C1_C", "C1_D", "C1_E", "C1_F", "C1_G", "C1_H", "C2", "C6", "C8_A", "C8_B", "C8_C", "C8_D",  "C9_1", "C10_A", "C10_B", "C10_1", "C11_A", "C11_B", "C11_C", "C11_D", "C11_E", "C11_G", "C11_H", "C11_I","D1", "D2", "D4", "E1", "E2", "E8", "F1_A", "F1_B", "F1_C", "F1_D", "F1_E", "F1_E", "F1_G","F8", "G1_A", "G1_B", "G1_C", "G1_D", "G1_E", "G1_F", "G1_G", "G1_H",  "G2",  "H1", "H2", "H3", "H4", "H5", "H7", "H10", "H17", "H18", "H19", "H20") 
## Train dataset
data.train.f<- data_target(data.train, target_var = "open_at_work", predictors = pred_var)
## Test dataset
data.test.f<- data_target(data.test, target_var = "open_at_work", predictors = pred_var)
```

```{r acc_val, echo=FALSE}
## 3d Function: Check for acceptable values
##########################################
## NOTE: Throughout the dataset,we have the following special values:
## -999: Don't know
## -777: Does not apply to me
## -888: Prefer not to say
## -1: Missing (for limited questions, applied only to "Other" category: "Please specify". So it is not a problem)
## -2: Not applicable
##########################################
## We should check for "-2" values in the set of auxiliary variables; Those should be probably converted to NA's
## Check if we have more variables, whether we should also insert an argument for specifying specific columns to be applied
repl_val<-function(data, val){
data<- data %>% 
   na_if(val) ##replace with NAs, the indicated values
return(data)
}
## Call the function
## Training dataset
data.train.frep<-repl_val(data.train.f,c("Not applicable"))
## Test dataset
data.test.frep<-repl_val(data.test.f,c("Not applicable"))
```


```{r reclass, echo=FALSE}
## 4th Function: Group response variable into two categories
regroup<-function(data, target_var){
data<- data %>% 
  mutate(!!as.name(target_var) := dplyr::recode(!!as.name(target_var), 'Very open'="Open", 'Selectively open'="Open"))
return(data)
}
## Call the function
## Training dataset
data.train.final<-regroup(data.train.frep, target_var="open_at_work")
## Test dataset
data.test.final<-regroup(data.test.frep, target_var="open_at_work")
```

#First tree (full)-With fixed Cp parameter
```{r tree_ML_tree1, echo=FALSE}
## Decision tree algorithm -- CART
library(rpart)
#### NOTE: Explanation of the parameters in the rpart formula ###
# Cp: complexity parameter --> avoids splitting those nodes that are obviously not worthwhile. 
# Cp value shall be determined after “growing the tree” and the optimal value is used to “prune the tree.”
# Cp: The default value is 0.01
# Cp: imposes a penalty to the tree for having two many splits. The higher the cp, the smaller the tree.
# minsplit: The minimum split criterion is the minimum number of records that must be present in a node before a split can be attempted
#######################################################
#######################################################
## STOP: If we do not restrict the Cp parameter, then we will receive the error below:
## Error in plot.rpart(tree1) : fit is not a tree, just a root.
## This occurs when the independent variables do not provide enough information to grow the tree. See, for example, the help for rpart. control: "Any split that does not decrease the overall lack of fit by a factor of cp is not attempted." 
## Trying loosening the control parameters, may result in the tree growing beyond a root.
#######################################################
########################################################
### Step 1. Run the procedure for the grouped target variable: "Open", "Hide LGBTI"
set.seed(1)
## Start with the model, using the default cp value: 0.01. A higher value in the complexity parameter, corresponds to a tree with just a root node
tree1b<-rpart(formula = open_at_work ~ ., data=data.train.final,  method = "class", parms= list(split = "information"), control = rpart.control(minsplit=1,cp=0.01, maxdepth=10 , usesurrogate= 0, maxsurrogate= 0))
## Step 2. Explore the results
printcp(tree1b)
## b. Detailed splitting process, Variables' importance, errors, etc.
summary(tree1b)
## c. Plot results
plot(tree1b)
text(tree1b,cex=0.5)
## d. Shows specifically variable importance
tree1b$variable.importance
## e. Plot relative error
plotcp(tree1b, upper="splits")
```

## First tree (full)-With relaxed Cp parameter allowing the tree to grow
```{r tree_ML_test, echo=FALSE}
########################################################
# Towards this approach to be adopted
########################################################
## Step 3. Run the model for the grouped outcome variable, by restricting cp to a lower value (i.e. permitting the tree to grow with more nodes). We run a more detailed tree and then prune it. 
set.seed(1)
tree1c<-rpart(formula = open_at_work ~ ., data=data.train.final,  method = "class", parms= list(split = "information"), control = rpart.control(minsplit=1,cp=0.001, maxdepth=10 , usesurrogate= 0, maxsurrogate= 0))
## Step 4. Explore the results
printcp(tree1c)
## c. Plot results
#par(xpd = NA) # otherwise on some devices the text is clipped
#plot(tree1c)
#text(tree1c,cex=0.5)
## d. Plot relative error
plotcp(tree1c, upper="splits")
## e. Variable importance
round(tree1c$variable.importance,1)
## f. Plot for Variable importance
tree1c$variable.importance %>% 
   data.frame() %>%
   rownames_to_column(var = "Feature") %>%
   rename(Overall = '.') %>%
   ggplot(aes(x = fct_reorder(Feature, Overall), y = Overall)) +
   geom_pointrange(aes(ymin = 0, ymax = Overall), color = "cadetblue", size = .3) +
   theme_minimal() +
   coord_flip() +
   labs(x = "", y = "", title = "Variable Importance with Simple Classication")
########################################################
## Step 4. Prune the tree. 
########################################################
#The decision on which node we should restrict the pruning should be taken on the basis of the relative error plot. We try to find a min value (below the dashed line)
## We have chosen 23 now, but this is not a clear minimum in the graph
node.c<-23
tree1c.pr <- prune(
   tree1c,
   cp = tree1c$cptable[tree1c$cptable[, 2] == node.c, "CP"]
)


## Step 5. Explore the results
printcp(tree1c.pr)
tree1c.pr$variable.importance
#plot(tree1c.pr)
#text(tree1c.pr,cex=0.5)
## Step 6. Measuring performance ###
## a. Derive confusion matrix
tree1c.pr.perf <- bind_cols(
   predict(tree1c.pr, newdata = data.test.final, type = "prob"),
   predicted = predict(tree1c.pr, newdata = data.test.final, type = "class"),
   actual = data.test.final$open_at_work
)
tree1c.pr.perf.ass <- caret::confusionMatrix(tree1c.pr.perf$predicted, reference = tree1c.pr.perf$actual)
tree1c.pr.perf.ass ## Shows a quite good accuracy of 0.88
## b. plot of the confusion matrix (actually we plot predicted vs. actual values)
plot(tree1c.pr.perf$actual, tree1c.pr.perf$predicted, 
     main = "Simple Classification: Predicted vs. Actual",
     xlab = "Actual",
     ylab = "Predicted")
## c. ROC Curve
library(Metrics)
library(yardstick)
mdl_tree1c.pr <- Metrics::auc(actual = tree1c.pr.perf$actual == "Open", tree1c.pr.perf$Open)
yardstick::roc_curve(tree1c.pr.perf, actual, Open) %>%
  autoplot() +
  labs(
    title = "OJ CART ROC Curve",
    subtitle = paste0("AUC = ", round(mdl_tree1c.pr, 4)))
```
